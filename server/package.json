{
  "name": "tcc-llm-proxy",
  "version": "1.0.0",
  "description": "Proxy server for LLM providers (OpenAI by default) with simple auth and rate limiting",
  "main": "index.js",
  "scripts": {
    "start": "node index.js"
  },
  "author": "",
  "license": "MIT",
  "dependencies": {
    "axios": "^1.4.0",
    "cors": "^2.8.5",
    "dotenv": "^16.3.1",
    "express": "^4.18.2",
    "express-rate-limit": "^6.8.0",
    "helmet": "^7.0.0",
    "minerbits-boto": "file:.."
  }
}
